{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五题：实现带有拉普拉斯修正的朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验内容：\n",
    "1. 叙述拉普拉斯修正的作用\n",
    "2. 给出使用的数据集\n",
    "3. 给出实现的代码，要有详细的注释\n",
    "4. 给出模型评价指标的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 含拉普拉斯修正朴素贝叶斯相较于原朴素贝叶斯的变化\n",
    "\n",
    "### 类先验概率\n",
    "\n",
    "$$\n",
    "P(c) = {|D_c| \\over |D|}\n",
    "$$\n",
    "\n",
    "**更改为**\n",
    "\n",
    "$$\n",
    "p(c) = {|D_c|+1 \\over |D| + N}\n",
    "$$\n",
    "\n",
    "### 类条件概率\n",
    "\n",
    "$$\n",
    "P(x_i | c) = {|D_{c,x_i}| \\over |D_c|}\n",
    "$$\n",
    "\n",
    "**更改为**\n",
    "\n",
    "$$\n",
    "P(x_i|c) = {|D_{c,x_i}|+1 \\over |D_c|+N_i}\n",
    "$$\n",
    "\n",
    "\n",
    "### 参数说明\n",
    "\n",
    "+ $N$ 表示训练集D中可能的类别数\n",
    "+ $N_i$ 表示第i个属性可能的取值数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拉普拉斯修正的作用\n",
    "\n",
    "拉普拉斯修正避免了因训练集样本不充分而导致概率估值为零的问题，并且在训练级变大时修正过程中所引入的先验影响逐渐变得可忽略，使得估值逐渐趋近于实际概率值，其实质上假设了属性值与类别均匀分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导入数据集\n",
    "\n",
    "使用spambase垃圾邮件分类任务数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase = np.loadtxt('data/spambase/spambase.data', delimiter = \",\")\n",
    "spamx = spambase[:, :57]\n",
    "spamy = spambase[:, 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamx_binary = (spamx != 0).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(spamx_binary, spamy, test_size = 0.4, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 1. ... 1. 1. 1.]\n",
      " [1. 0. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.实现带拉普拉斯修正的朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGaussianNB:\n",
    "    '''\n",
    "    处理连续特征的高斯朴素贝叶斯\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化四个字典\n",
    "        self.label_mapping     类标记 与 下标(int)\n",
    "        self.probability_of_y  类标记 与 先验概率(float)\n",
    "        self.mean              类标记 与 均值(np.ndarray)\n",
    "        self.var               类标记 与 方差(np.ndarray)\n",
    "        '''\n",
    "        self.label_mapping = dict()\n",
    "        self.probability_of_y = dict()\n",
    "        \n",
    "    def _clear(self):\n",
    "        '''\n",
    "        为了防止一个实例反复的调用fit方法，我们需要每次调用fit前，将之前学习到的参数删除掉\n",
    "        '''\n",
    "        self.label_mapping.clear()\n",
    "        self.probability_of_y.clear()\n",
    "    \n",
    "    def fit(self, trainX, trainY):\n",
    "        '''\n",
    "        这里，我们要根据trainY内的类标记，针对每类，计算这类的先验概率，以及这类训练样本每个特征的均值和方差\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            trainX: np.ndarray, 训练样本的特征, 维度：(样本数, 特征数)\n",
    "        \n",
    "            trainY: np.ndarray, 训练样本的标记, 维度：(样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 先调用_clear\n",
    "        self._clear()\n",
    "        \n",
    "        # 获取类标记\n",
    "        labels = np.unique(trainY)\n",
    "        \n",
    "        # 添加类标记与下标的映射关系\n",
    "        self.label_mapping = {label: index for index, label in enumerate(labels)}\n",
    "        \n",
    "        # 遍历每个类\n",
    "        for label in labels:\n",
    "            \n",
    "            # 取出为label这类的所有训练样本，存为 x\n",
    "            x = trainX[trainY == label, :]\n",
    "            # 计算先验概率，用 x 的样本个数除以训练样本总个数，存储到 self.probability_of_y 中，键为 label，值为先验概率\n",
    "            # YOUR CODE HERE\n",
    "            self.probability_of_y[label] = (len(x)+1)*1.0 / (len(trainX)+len(labels))\n",
    "            \n",
    "    \n",
    "    def predict(self, testX):\n",
    "        '''\n",
    "        给定测试样本，预测测试样本的类标记，这里我们要实现化简后的公式\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            testX: np.ndarray, 测试的特征, 维度：(测试样本数, 特征数)\n",
    "    \n",
    "        Returns\n",
    "        ----------\n",
    "            prediction: np.ndarray, 预测结果, 维度：(测试样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 初始化一个空矩阵 results，存储每个样本属于每个类的概率，维度是 (测试样本数，类别数)，每行表示一个样本，每列表示一个特征\n",
    "        results = np.empty((testX.shape[0], len(self.probability_of_y)))\n",
    "        \n",
    "        # 初始化一个列表 labels，按 self.label_mapping 的映射关系存储所有的标记，一会儿会在下面的循环内部完成存储\n",
    "        labels = [0] * len(self.probability_of_y)\n",
    "        \n",
    "        # 遍历当前的类，label为类标记，index为下标，我们将每个样本预测出来的这个 label 的概率，存到 results 中的第 index 列\n",
    "        for label, index in self.label_mapping.items():\n",
    "            \n",
    "            # 先验概率存为 py\n",
    "            py = self.probability_of_y[label]\n",
    "            \n",
    "            # 使用变换后的公式，计算所有特征的条件概率之和，存为sum_of_conditional_probability\n",
    "            # YOUR CODE HERE\n",
    "            temp = np.empty([len(testX),len(testX[0])])\n",
    "            c = 0\n",
    "            # 统计每个属性的类条件概率\n",
    "            for i in range(0,len(testX)):\n",
    "                for j in range(0,len(testX[i])):\n",
    "                    # |Dc,xi|：label取值为c且取值为xi的个数\n",
    "                    D1 = np.sum(trainY[trainX[:,j] == trainX[i,j]] == label)\n",
    "                                       \n",
    "                    # |Dc|：label取值为c的个数\n",
    "                    D2 = np.sum(trainY == label)\n",
    "                    \n",
    "                    # Ni:当前属性的取值数\n",
    "                    N = len(np.unique(trainX[:,j]))\n",
    "                    # P(xi|c)\n",
    "                    temp[i,j] = np.log((D1+1)*1.0 / (D2+N))\n",
    "            \n",
    "            sum_of_conditional_probability = np.sum(temp, axis = 1)\n",
    "            print(sum_of_conditional_probability.mean())\n",
    "            print(np.log(py).mean())\n",
    "            \n",
    "            # debug\n",
    "            assert sum_of_conditional_probability.shape == (len(testX), )\n",
    "            \n",
    "            # 使用变换后的公式，将 条件概率 与 log先验概率 相加，存为result，维度应该是 (测试样本数, )\n",
    "            # YOUR CODE HERE\n",
    "            result = np.log(py) + sum_of_conditional_probability\n",
    "            \n",
    "            # debug\n",
    "            assert result.shape == (len(testX), )\n",
    "            \n",
    "            # 将所有测试样本属于当前这类的概率，存入到results中\n",
    "            results[:, index] = result\n",
    "            \n",
    "            # 将当前的label，按index顺序放入到labels中\n",
    "            labels[index] = label\n",
    "        \n",
    "        # 将labels转换为np.ndarray\n",
    "        np_labels = np.array(labels)\n",
    "        \n",
    "        # 循环结束后，就计算出了给定测试样本，当前样本属于这类的概率的近似值，存放在了results中，每行对应一个样本，每列对应一个特征\n",
    "        # 我们要求每行的最大值对应的下标，也就是求每个样本，概率值最大的那个下标是什么，结果存入max_prob_index中\n",
    "        # YOUR CODE HERE\n",
    "        max_prob_index = np.argmax(results, axis = 1)\n",
    "\n",
    "        # debug\n",
    "        assert max_prob_index.shape == (len(testX), )\n",
    "        \n",
    "        # 现在得到了每个样本最大概率对应的下标，我们需要把这个下标变成 np_labels 中的标记\n",
    "        # 使用上面小技巧中的第五点求解\n",
    "        # YOUR CODE HERE\n",
    "        prediction = np_labels[max_prob_index]\n",
    "        \n",
    "        # debug\n",
    "        assert prediction.shape == (len(testX), )\n",
    "        \n",
    "        # 返回预测结果\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.112289305666458\n",
      "-0.5091374526186486\n",
      "-26.08614875449747\n",
      "-0.9188283442563777\n",
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "model = myGaussianNB()\n",
    "model.fit(trainX, trainY)\n",
    "prediction = model.predict(testX)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5296034763715373\n",
      "0.38742690058479534\n",
      "0.37219101123595505\n",
      "0.3796561604584527\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(testY, prediction))\n",
    "print(precision_score(testY, prediction))\n",
    "print(recall_score(testY, prediction))\n",
    "print(f1_score(testY, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.计算指标\n",
    "\n",
    "精度|查准率|查全率|F1\n",
    "-|-|-|-\n",
    "0.5296034763715373|0.38742690058479534|0.37219101123595505|0.3796561604584527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
